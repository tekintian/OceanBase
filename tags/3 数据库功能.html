<p>数据库功能层构建在分布式存储引擎层之上，实现完整的关系数据库功能。</p>
<p>对于使用者来说，OceanBase与Mysql数据库并没有什么区别，可以通过Mysql客户端连接OceanBase，也可以在程序中通过JDBC/ODBC操作OceanBase。OceanBase的MergeServer模块支持Mysql协议，能够将其中的SQL请求解析出来，并转化为OceanBase系统的内部调用。</p>
<p>OceanBase定位为全功能的关系数据库，但这并不代表我们会同等对待所有的关系数据库功能。关系数据库系统中优化器是最为复杂的，这个问题困扰了关系数据库几十年，更不可能是OceanBase的长项。因此，OceanBase支持的SQL语句一般比较简单，绝大部分为针对单张表格的操作，只有很少一部分操作涉及到多张表格。OceanBase内部将事务划分为只读事务和读写事务，只读事务执行过程中不需要加锁，读写事务最终需要发给UpdateServer执行。相比传统的关系数据库，OceanBase执行简单的SQL语句要高效得多。</p>
<p>除了支持OLTP业务，OceanBase还能够支持OLAP业务。OLAP业务的查询请求并发数不会太高，但每次查询的数据量都非常大。为此，OceanBase设计了并行计算框架和列式存储来处理OLAP业务面临的大查询问题。</p>
<p>最后，OceanBase还针对实际业务的需求开发了很多特色功能，例如：用于淘宝网收藏夹的大表左连接功能，数据自动过期以及批量删除功能。这些功能在关系数据库中要么不支持，要么效率很低，不能满足业务的需求，我们将这些需求通用化后集成到OceanBase系统中。</p>
<h2>3.1  整体结构</h2>
<p>如<b><a href="#f_3_1">图3-1</a></b>，用户可以通过兼容Mysql协议的客户端，JDBC/ODBC等方式将SQL请求发送给某一台MergeServer。MergeServer的Mysql协议模块将解析出其中的SQL语句，并交给MS-SQL模块进行词法分析（采用GNU Flex实现）、语法分析（采用GNU Bison实现）、预处理、并生成逻辑执行计划和物理执行计划。</p>
<p><b><a name="f_3_1" id="f_3_1"></a>图3-1 数据库功能层整体结构</b></p>
<p><IMG alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_1.png?raw=true"></p>
<p>如果是只读事务，MergeServer首先定位请求的数据所在的ChunkServer，接着往相应的ChunkServer发送SQL子请求，每个ChunkServer将调用CS-SQL模块计算SQL子请求的结果，并将计算结果返回给MergeServer。最后，MergeServer需要整合这些子请求的返回结果，执行结果合并、联表、子查询等操作，得到最终结果并返回给客户端。</p>
<p>如果是读写事务，MergeServer首先从ChunkServer中读取需要的基线数据，接着将物理执行计划以及基线数据一起发送给UpdateServer，UpdateServer将调用UPS-SQL模块完成写事务。</p>
<UL>
  <LI>
    <p>CS-SQL：实现针对单个Tablet的SQL查询，包括表格扫描（table scan）、投影（projection）、过滤（filter）、排序（order by）、分组（group by）、分页（limit），支持表达式计算、聚集函数（count/sum/max/min等）。执行表格扫描时，需要从UpdateServer读取修改增量，与本地的基准数据合并。</p>
  </LI>
  <LI>
    <p>UPS-SQL：实现写事务，支持的功能包括多版本并发控制、操作日志多线程并发回放等。</p>
  </LI>
  <LI>
    <p>MS-SQL：SQL语句解析，包括词法分析、语法分析、预处理、生成执行计划，按照Tablet范围合并多个ChunkServer返回的部分结果，实现针对多个表格的物理操作符，包括联表（Join），子查询（subquery）等。</p>
  </LI>
</UL>
<h2>3.2  只读事务</h2>
<p>只读事务（SELECT语句），经过词法分析、语法分析、预处理后，转化为逻辑查询计划和物理查询计划。逻辑查询计划的改进和物理查询计划的选择（即查询优化器）是关系数据库最难的部分，OceanBase目前在这一部分的工作不多，因此本节不会涉及太多关于如何生成物理查询计划的内容。下面仅以两个例子说明OceanBase的物理查询计划。</p>
<p>例1：有一个单表SQL语句，如<a href="#f_3_2"><b>图3-2</b></a>所示。</p>
<p><b><a name="f_3_2" id="f_3_2"></a>图3-2 单表物理查询计划示例</b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_2.png?raw=true" /></p>
<p><a href="#f_3_2"><b>图3-2</b></a>中的单表SQL语句执行过程如下：</p>
<ol>
  <li>
    <p>调用TableScan操作符，读取table t1中的数据，该操作符还将执行投影（Project）和过滤（Filter），返回的结果只包含c3=10的数据行，且每行只包含c1、c2、c3三列。</p>
  </li>
  <li>
    <p>调用HashGroupBy操作符（假设采用基于哈希的分组算法），按照c1对数据分组，同时计算每个分组内c2列的总和。</p>
  </li>
  <li>
    <p>调用Filter操作符，过滤分组后生成的结果，只返回上一层sum(c2) &gt;= 10的行。</p>
  </li>
  <li>
    <p>调用Sort操作符将结果按照c1排序。</p>
  </li>
  <li>
    <p>调用Project操作符，只返回c1和sum(c2)这两列数据。</p>
  </li>
  <li>
    <p>调用Limit操作符执行分页操作，只返回前20条数据。</p>
  </li>
</ol>
<p>例2：有一个需要联表的SQL语句，如<a href="#f_3_3"><b>图3-3</b></a>所示。</p>
<p><b><a name="f_3_3" id="f_3_3"></a>图3-3 多表物理查询计划示例</b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_3.png?raw=true" /></p>
<p><a href="#f_3_3"><b>图3-3</b></a>中的多表SQL语句执行过程如下： </p>
<ol>
  <li>
    <p>调用TableScan分别读取t1和t2的数据。对于t1，使用条件c3=10对结果进行过滤，t1和t2都只需要返回c1、c2、c3这三列数据。</p>
  </li>
  <li>
    <p>假设采用基于排序的表连接算法，t1和t2分别按照t1.c2和t2.c2排序后，调用MergeJoin运算符，以t1.c2=t2.c2为条件执行等值连接。</p>
  </li>
  <li>
    <p>调用HashGroupBy运算符（假设采用基于哈希的分组算法），按照t1.c1对数据分组，同时计算每个分组内t2.c3列的总和。</p>
  </li>
  <li>
    <p>调用Filter运算符，过滤分组后的生成的结果，只返回上一层sum(t2.c3) &gt;= 10的行。</p>
  </li>
  <li>
    <p>调用Sort操作符将结果按照t1.c1排序。</p>
  </li>
  <li>
    <p>调用Project操作符，只返回t1.c1和sum(t2.c3)这两列数据。</p>
  </li>
  <li>
    <p>调用Limit操作符执行分页操作，只返回前20条数据。</p>
  </li>
</ol>
<h3>3.2.1   物理操作符接口</h3>
<p>在本手册的“2.3.1   SSTable”中介绍了一期分布式存储引擎的迭代器接口为ObIterator。通过它，可以将读到的数据以cell为单位逐个迭代。然而，数据库操作总是以行为单位的，因此二期实现数据库功能层时考虑将基于cell的迭代器修改为基于行的迭代器。</p>
<p>行迭代器接口如下： </p>
<pre>// 物理运算符接口             
  class ObPhyOperator        
  {         
    public:       
  // 添加子运算符，所有非叶子节点物理运算符都需要调用该接口  。     
    virtual int set_child(int32_t child_idx, ObPhyOperator &amp;child_operator);        

  // 打开物理运算符。申请资源，打开子运算符等。     
    virtual int open() = 0;     
  // 关闭物理运算符。释放资源，关闭子运算符等。     
    virtual int close() = 0;           
 
  // 获得下一行数据内容      
  // @param=out] row 下一行数据内容的引用      
  // @return 返回码，包括成功、迭代过程中出现错误以及迭代完成      
    virtual int get_next_row(const ObRow *&amp;row) = 0;     
   };  </pre>
<pre>// ObRow表示一行数据内容     
  class ObRow       
  {        
    public:       
  // 根据表ID以及列ID获得指定cell       
  // @param =in] table_id 表格ID       
  // @param =in] column_id 列ID       
  // @param =out] cell 读到的cell       
    int get_cell(const uint64_t table_id, const uint64_t column_id, ObObj *&amp;cell);         

  // 获取低cell_idx个cell       
    int raw_get_cell(const int64_t cell_idx, const ObObj *&amp;cell, uint64_t &amp;table_id, uint64_t &amp;column_id);          

  // 获取本行的列数       
    int64_t get_column_num() const;     
};  </pre>
<p>每一行数据（ObRow）包括多个列，每个列的内容包括所在的表ID（table_id），列ID（column_id）以及列内容（cell）。ObRow提供两种访问方式：“根据table_id和column_id随机访问某个列”和“根据cell_idx获取下一个列”。</p>
<p>ObPhyOperator每次获取一行数据，使用方法如下：</p>
<pre>ObPhyOperator root_operator = root_operator_;// 根运算符    
root_operator-&gt;open();    
ObRow *row = NULL;    
while (OB_SUCCESS == root_operator-&gt;get_next_row(row))    
{        
      Output(row); //输出本行    
}    
root_operator-&gt;close(); </pre>
<p>为什么ObPhyOperator类中有一个set_child接口呢？这是因为所有的物理运算符构成一颗树，每个物理运算的输出结果都可以认为是一个临时的二维表，树中孩子节点的输出总是作为它的父亲节点的输入。在“3.2  只读事务”的“例1”中，叶子节点为一个TableScan类型的物理运算符（称为table_scan_op），它的父亲节点为一个HashGroupBy类型的物理运算符（称为hash_group_by_op），接下来依次为Filter类型物理运算符filter_op，Sort类型物理运算符sort_op，Project类型物理运算符project_op，Limit类型物理运算符limit_op。其中，limit_op为根运算符。那么，生成物理运算符时将执行如下语句： </p>
<pre>limit_op-&gt;set_child(0, project_op);    
project_op-&gt;set_child(0, sort_op);    
sort_op-&gt;set_child(0, filter_op);    
filter_op-&gt;set_child(0, hash_group_by_op);    
hash_group_by_op-&gt;set_child(0, table_scan_op);    
root_operator = limit_op; </pre>
<pre>SQL最终执行时，只需要迭代root_operator就可以依次迭代出所需的数据。</pre>
<h3>3.2.2 单表操作</h3>
<p>单表相关的物理运算符包括：</p>
<ul>
  <li>TableScan<br />
  扫描某个表格。MergeServer将扫描请求发给请求的各个Tablet所在的ChunkServer，并将ChunkServer返回的结果按照Tablet范围拼接起来作为输出。如果请求涉及到多个Tablet，TabletScan可由多台ChunkServer并发执行。</li>
  <li>Filter<br />
  针对每行数据，判断是否满足过滤条件。</li>
  <li>Projection<br />
  对输入的每一行，根据定义的输出表达式，计算输出结果行。</li>
  <li>GroupBy<br />
  把输入数据按照指定列进行聚集，对聚集后的每组数据可以执行count、sum、min、max、avg等聚集操作。</li>
  <li>Sort<br />
  对输入数据进行整体排序，如果内存不够，需要使用外排序。</li>
  <li>Limit<br />
  返回行号在=offset, offset + count)范围内的行。</li>
  <li>Distinct<br />
  消除某些列的重复行。</li>
</ul>
<p>GroupBy、Distinct物理操作符可以通过基于排序的算法实现，也可以通过基于哈希的算法实现，分别对应HashGroupBy&amp;MergeGroupBy，以及HashDistinct&amp;MergeDistinct。下面分别讨论排序算法和哈希算法：</p>
<ul>
  <li> 排序算法<br />
  MergeGroupBy、MergeDistinct以及Sort都需要使用排序算法。通用的&lt;key, value&gt;排序器可以分为两个阶段：
  <ol>
    <li>数据收集。<br />
    在数据收集阶段，调用者将&lt;key, value&gt;对依次加入到排序器。如果数据总量超过排序器的内存上限，需要首先将内存中的数据排好序，并存储到外部磁盘中。</li>
    <li>迭代输出。<br />
    迭代第一行数据时，内存中可能有一部分未排序的数据，磁盘中也可能有几路已经排序的数据。因此，首先将内存中的数据排序。如果数据总量不超过排序器的内存上限，那么将内存中已经排序的数据按行迭代输出（内排序）；否则，对内存和磁盘中的部分有序数据执行多路归并，一边归并一边将结果迭代输出。</li>
  </ol></li>
  <li> 哈希算法<br />
  HashGroupBy以及HashDistinct都需要使用哈希算法。假设需要对&lt;key, value&gt;对按照key分组，那么首先使用key计算哈希值K，并将这个&lt;key, value&gt;对写入到第K个桶中。不同的key可能对应相同的哈希桶，因此，还需要对每个哈希桶内的&lt;key, value&gt;排序，使key相同的元组能够连续迭代。哈希算法的难点在于数据总量超过内存上限的处理，由于篇幅有限，请自行思考。</li>
</ul>
<h3>3.2.3	多表操作</h3>
<p>多表相关的物理操作符主要是Join。最为常见的Join类型包括两种：内连接（Inner Join）和左外连接（Left Outer Join），而且基本都是等值连接。如果需要Join多张表，可以先Join前两张表，再将前两张表Join生成的结果（相当于一张临时表）与第三张表格Join，以此类推。</p>
<p>两张表实现等值连接方式主要分为两类：基于排序的算法（MergeJoin）以及基于哈希的算法（HashJoin）。对于MergeJoin，首先使用Sort运算符分别对输入表格预处理，使得两张输入表都在Join列上排序，接着按顺序迭代两张输入表，合并Join列相同的行并输出；对于HashJoin，首先根据Join列计算哈希值K，并分别将两张输入表格的数据写入到第K个桶中。接着，对每个哈希桶按照Join列排序。最后，依次对每个哈希桶合并Join列相同的行并输出。</p>
<p>子查询分为两种：关联子查询和非关联子查询，其中比较常用的是使用IN子句的非关联子查询。举例如下：</p>
<p>假设有两张表分别为item（商品表，包括商品号item_id，商品名item_name，分类号category_id）和category（类别表，包括分类号category_id，分类名category_name）。</p>
<p>如果需要查询分类号出现在category表中商品，可以采用<a href="#f_3_4"><b>图3-4</b></a>左边的IN子查询，而这个子查询将被自动转化为<a href="#f_3_4"><b>图3-4</b></a>右边的等值连接。如果category表中的category_id列有重复，表连接之前还需要使用distinct运算符来删除重复的记录。</p>
<p><b><a name="f_3_4" id="f_3_4"></a>图3-4 IN子查询转化为等值连接 </b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_4.png?raw=true" /></p>
<p>如果category表只包含category_id为1~10的记录，那么，可以将IN子查询转化为<a href="#f_3_5"><b>图3-5</b></a>右边的常量表达式。</p>
<p><b><a name="f_3_5" id="f_3_5"></a>图3-5 IN子查询转化为常量表达式 </b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_5.png?raw=true" /></p>
<p>转化为常量表达式后，MergeServer执行SQL计算时，可以将IN后面的常量列表发送给ChunkServer，ChunkServer只返回category_id在category表中的商品记录，而不是将所有的记录返回给MergeServer过滤，从而减少二者之间传输的数据量。</p>
<h3>3.2.4   SQL执行本地化</h3>
<p>MergeServer包含SQL执行模块MS-SQL，ChunkServer也包含SQL执行模块CS-SQL，那么如何区分二者的功能呢？多表操作由MergeServer执行；对于单表操作，OceanBase设计的基本原则是尽量支持SQL计算本地化，保持数据节点与计算节点一致，也就是说，只要ChunkServer能够实现的操作，原则上都应该由它来完成。</p>
<ul>
  <li>
    <p>TableScan<br />
    每个ChunkServer扫描各自Tablet范围内的数据，由MergeServer合并ChunkServer返回的部分结果。</p>
  </li>
  <li>
    <p>Filter<br />
    对基本表的过滤集成在TableScan操作符中，由ChunkServer完成。对分组后的结果执行过滤（Having）集成在GroupBy操作符中，一般情况下由MergeServer完成；但是，如果能够确定每个分组的所有数据行只属于同一个Tablet，比如SQL请求只涉及一个Tablet，那么，分组以及分组后的过滤操作符可以由ChunkServer完成。</p>
  </li>
  <li>
    <p>Projection<br />
    对基本表的投影集成在TableScan操作符中，由ChunkServer完成，对最终结果的投影由MergeServer完成。</p>
  </li>
  <li>
    <p>GroupBy<br />
    如果SQL读取的数据只在一个Tablet上，那么由该Tablet所在的ChunkServer完成分组操作；否则每台ChunkServer各自完成部分数据的分组操作，执行聚合运算后得到部分结果，再由MergeServer合并所有ChunkServer返回的部分结果，对于属于同一个分组的数据再次执行聚合运算。某些聚合运算需要做特殊处理，比如avg，需要转化为sum和count操作发送给ChunkServer，MergeServer合并ChunkServer返回的部分结果后计算出最终的sum和count值，并通过“sum/count”得到avg的最终结果。</p>
  </li>
  <li>
    <p>Sort<br />
    如果SQL读取的数据只在一个Tablet上，那么由该Tablet所在的ChunkServer完成排序操作；否则每台ChunkServer各自完成部分数据的排序，并将排序部分数据返回MergeServer，再由MergeServer执行多路归并。</p>
  </li>
  <li>
    <p>Limit<br />
    Limit操作一般由MergeServer完成，但是如果请求的数据只在一个Tablet上，可以由ChunkServer完成，这往往会大大减少MergeServer与ChunkServer之间传输的数据量。</p>
  </li>
  <li>
    <p>Distinct<br />
    Distinct与GroupBy类似。ChunkServer先完成消除部分数据的的重复行，再由MergeServer进行整体消除数据的重复行。</p>
  </li>
</ul>
<p>例如：<b><a href="#f_3_2">图3-2</a></b>中的SQL语句为“select c1, sum(c2) from t1 where c3 = 10 group by c1 having sum(c2) &gt;= 10 orderby c1 limit 0, 20”。执行步骤如下：</p>
<ol>
  <li>
    <p>ChunkServer调用TableScan操作符，读取table t1中的数据，该操作符还将执行投影（Project）和过滤（Filter），返回的结果只包含c3=10的数据行，且每行只包含c1、c2、c3三列。</p>
  </li>
  <li>
    <p>ChunkServer调用HashGroupBy操作符（假设采用基于哈希的分组算法），按照c1对数据分组，同时计算每个分组内c2列的总和sum(c2)。</p>
  </li>
  <li>
    <p>每个ChunkServer将分组后的部分结果返回MergeServer，MergeServer将来自不同ChunkServer的c1列相同的行合并在一起，再次执行sum运算。</p>
  </li>
  <li>
    <p>MergeServer调用Filter操作符，过滤“步骤3”生成的最终结果，只返回sum(c2) &gt;= 10的行。</p>
  </li>
  <li>
    <p>MergeServer调用Sort操作符将结果按照c1排序。</p>
  </li>
  <li>
    <p>MergeServer调用Project操作符，只返回c1和sum(c2)这两列数据。</p>
  </li>
  <li>
    <p>MergeServer调用Limit操作符执行分页操作，只返回前20条数据。</p>
  </li>
</ol>
<p>如果能够确定请求的数据全部属于同一个Tablet，那么，所有的物理运算符都可以由ChunkServer执行，MergeServer只需要将ChunkServer计算得到的结果转发给客户端。</p>
<h2>3.3  写事务</h2>
<p>写事务包括UPDATE、INSERT、DELETE和REPLACE。由MergeServer解析后生成物理执行计划，这个物理执行计划最终将发给UpdateServer执行。写事务可能需要读取基线数据，用于判断更新或者插入的数据行是否存在，判断某个条件是否满足等，这些基线数据也会由MergeServer传给UpdateServer。</p>
<h3>3.3.1   写事务执行流程</h3>
<p>大部分写事务都是针对单行的操作，如果单行写事务不带其它条件：</p>
<ul>
  <li>
    <p>REPLACE<br />
    REPLACE事务不关心写入行是否已经存在，因此MergeServer直接将修改操作发送给UpdateServer执行。</p>
  </li>
  <li>
    <p>INSERT<br />
    MergeServer首先读取ChunkServer中的基线数据，并将基线数据中行是否存在信息发送给UpdateServer。UpdateServer接着查看增量数据中行是否被删除或者有新的更新操作，融合基线数据和增量数据后，如果行不存在，则执行插入操作；否则，返回行已存在错误。</p>
  </li>
  <li>
    <p>UPDATE<br />
    与INSERT事务执行步骤类似，不同点在于，行已存在则执行更新操作；否则返回行不存在错误。</p>
  </li>
  <li>
    <p>DELETE<br />
    与UPDATE事务执行步骤类似。如果行已存在则执行删除操作；否则返回行不存在错误。</p>
  </li>
</ul>
<p>如果单行写事务带有其它条件：</p>
<ul>
  <li>
    <p>UPDATE<br />
    如果UPDATE事务带有其它条件，那么MergeServer除了从基线数据中读取行是否存在，还需要读取用于条件判断的基线数据，并传给UpdateServer。UpdateServer融合基线数据和增量数据后，执行条件判断，如果行存在且判断条件成立则执行更新操作，否则返回行已存在或者条件不成立错误。</p>
  </li>
  <li>
    <p>DELETE<br />
    与UPDATE事务执行步骤类似。</p>
  </li>
</ul>
<p>例1：有一张表格item（user_id, item_id，item_status，item_name），其中&lt;user_id, item_id&gt;为联合主键。</p>
<ol>
  <li>MergeServer首先解析<a href="#f_3_6"><b>图3-6</b></a>的SQL语句产生执行计划，确定待修改行的主键为&lt;1，2&gt;。</li>
  <li>请求主键&lt;1，2&gt;所在的ChunkServer，获取基线数据中行是否存在。</li>
  <li>将SQL执行计划和基线数据中行是否存在一起发送给UpdateServer。</li>
  <li>UpdateServer融合基线数据和增量数据，如果行已存在且未被删除，UPDATE和DELETE语句执行成功，INSERT语句执行返回“行已存在”；如果行不存在或者最后被删除，INSERT语句执行成功，UPDATE和DELETE语句返回“行不存在”。</li>
</ol>
<p><b><a name="f_3_6" id="f_3_6"></a>图3-6 单行写事务（不带条件）</b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_6.png?raw=true" /></p>
<p>如<b><a href="#f_3_7">图3-7</a></b>所示，UPDATE和DELETE语句带有item_name = “item1”的条件时，MergeServer除了请求ChunkServer获取基线数据中行是否存在，还需要获取item_name的内容，并将这些信息一起发送给UpdateServer。UpdateServer融合基线数据和增量数据，判断最终结果中行是否存在，以及item_name的内容是否为“item1”，只有两个条件同时成立，UPDATE和DELETE语句才能够执行成功；否则，返回“行不存在或者item_name列的最终值”。</p>
<p><b><a name="f_3_7" id="f_3_7"></a>图3-7 单行写事务（带条件）</b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_7.png?raw=true" /></p>
<p>当然，并不是所有的写事务都这么简单。复杂的写事务可能需要修改多行数据，事务执行过程也可能比较复杂。</p>
<p>例2：有两张表格分别为item（user_id, item_id, item_status, item_name）和user（user_id，user_name）。其中&lt;user_id, item_id&gt;为item表格的联合主键，user_id为user表格的主键。</p>
<p>如<b><a href="#f_3_8">图3-8</a></b>所示，UPDATE语句可能会更新多行。MergeServer首先从ChunkServer获取编号为“1”的用户，包含的全部item（可能包含多行），并传给UpdateServer。接着，UpdateServer融合基线数据和增量数据，更新每个存在且未被删除的item的item_status列。</p>
<p><b><a href="#f_3_8">图3-8</a></b>中的DELETE语句更加复杂，执行时需要首先获取user_name为“张三”的用户的user_id，考虑到事务隔离级别，这里可能需要锁住user_name为“张三”的数据行（防止user_name被修改为其它值）甚至锁住整张user表（防止其它行的user_name修改为“张三”或者插入user_name为“张三”的新行）。接着，获取用户名为“张三”的所有用户的所有item，最后，删除这些item。这条语句执行的难点在于如何降低锁粒度以及锁占用时间，具体的做法请读者自行思考。</p>
<p><b><a name="f_3_8" id="f_3_8"></a>图3-8 复杂写事务举例</b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_8.png?raw=true" /></p>
<h3>3.3.2   多版本并发控制</h3>
<p>OceanBase MemTable底层数据结构为一颗内存B+树，支持多线程并发修改。</p>
<h4>* 并发修改B+树</h4>
<p>MemTable的索引结构是一颗支持多线程并发修改的B+树。<b><a href="#f_3_9">图3-9</a></b>说明了并发修改B+树的实现原理。</p>
<ul>
  <li>两个线程分别插入Data1和Data2：由于Data1和Data2用于不同的父亲节点，插入Data1和Data2将影响B+树的不同部分，两个线程可以并发执行，不会产生冲突。</li>
  <li>两个线程分别插入Data2和Data3：由于Data2和Data3拥有相同的父亲节点，因此，插入操作将产生冲突。其中一个线程会执行成功，另外一个线程失败后将重试。</li>
</ul>
<p><b><a name="f_3_9" id="f_3_9"></a>图3-9 并发修改B+树</b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_9.png?raw=true" /></p>
<p>另外，每个索引节点满了以后将分裂为两个节点，并触发对该索引节点的父亲节点的修改操作。分裂操作将增加插入线程冲突的概率，在<b><a href="#f_3_9">图3-9</a></b>中，假设Data1和Data2的父亲节点都需要分裂，那么插入线程需要分别修改Data1和Data2的祖父节点，从而产生冲突。</p>
<p>B+树结构以行为单位索引MemTable中的数据，支持的功能如下：</p>
<ul>
  <li>
    Put<br />
  插入一行数据。MemTable每次插入一行数据需要往B+树索引结构中增加一个&lt;key, value&gt;对，其中，key为该行数据的主键，value为该行实际内容的头部信息。  </li>
  <li>Get<br />
  根据主键读取一行的内容。</li>
  <li>Scan<br />
  扫描一段范围内的数据行。</li>
</ul>
<p>细心的读者可能会发现，这里的B+树不支持更新（Update）以及删除操作，这是由MVCC存储引擎的实现机制决定的。MVCC存储引擎内部将删除操作实现为标记删除，即在行的末尾追加一个单元记录行的删除时间，而不会物理删除某行数据。</p>
<h4>* 多版本并发机制</h4>
<p>OceanBase支持多线程并发修改，写操作拆分为两个阶段：</p>
<ol>
  <li>
    预提交（多线程执行）。<br />
    事务执行线程首先锁住待更新数据行。接着，将事务中针对数据行的操作追加到该行的未提交行操作链表中。最后，往提交任务队列中加入一个提交任务。
  </li>
  <li>提交（单线程执行）。<br />
  提交线程不断地扫描并取出提交任务队列中的提交任务，将这些任务的操作日志追加到日志缓冲区中。如果日志缓冲区到达一定大小，将日志缓冲区中的数据同步到备机，同时写入主机的磁盘日志文件。操作日志写成功后，将未提交行操作链表中的cell操作追加到已提交行操作链表的末尾，释放锁并回复客户端写操作成功。</li>
</ol>
<p>如<a href="#f_3_10"><b>图3-10</b></a>所示，MemTable行操作链表包含两个部分：已提交部分和未提交部分。另外，每个Session记录了当前事务正在操作的数据行的行头，每个数据行的行头包含已提交和未提交行操作链表的头部指针。在预提交阶段，每个事务会将cell操作追加到未提交行操作链表中，并在行头保存未提交行操作链表的头部指针以及锁信息，同时，将行头信息记录到Session中；在提交阶段，根据Session中记录的行头信息找到未提交行操作链表，链接到已提交行操作链表的末尾，并释放行头记录的锁。</p>
<p><b><a name="f_3_10" id="f_3_10"></a>图3-10 MemTable实现MVCC</b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_10.png?raw=true" /></p>
<p>每个写事务会根据提交时的系统时间生成一个事务版本，读事务只会读取在它之前提交的写事务的修改操作。</p>
<p>如<a href="#f_3_11"><b>图3-11</b></a>所示，对主键为1的商品有2个写事务，事务T1（提交版本号为2）将商品购买人数修改为100，事务T2（提交版本号为4）将商品购买人数修改为50。那么，事务T2预提交时，T1已经提交，该商品的已提交行操作链包含一个cell：&lt;update，购买人数，100&gt;，未提交操作链包含一个cell：&lt;update, 购买人数, 50&gt;。事务T2成功提交后，该商品的已提交行操作链将包含两个cell：&lt;update，购买人数，100&gt;以及&lt;update，购买人数，50&gt;，以及，未提交行操作链为空。对于只读事务：</p>
<p>(1) T3：事务版本号为1，T1和T2均未提交，该行数据为空。<br />
  (2) T4：事务版本号为3，T1已提交，T2未提交，读取到&lt;update，购买人数，100&gt;。尽管T2在T4执行过程中将购买人数修改为50，T4第二次读取时会过滤掉T2的修改操作，因而两次读取将得到相同的结果。<br />
  (3) T5：事务版本号为5，T1和T2均已提交，读取到&lt;update, 购买人数, 100&gt;以及&lt;update，购买人数，50 &gt;，购买人数最终值为50。</p>
<p><b><a name="" id=""></a>图3-11 读写事务并发执行实例</b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_11.png?raw=true" /></p>
<h4>* 锁机制</h4>
<p>OceanBase锁定粒度为行锁，默认情况下的隔离级别为read committed。另外，读操作总是读取某个版本的快照数据，不需要加锁。</p>
<ul>
  <li>只写事务（修改单行）<br />
  事务预提交时对待修改的数据行加写锁，事务提交时释放写锁。</li>
  <li>只写事务（修改多行）<br />
  事务预提交时对待修改的多个数据行加写锁，事务提交时释放写锁。为了保证一致性，采用两阶段锁的方式实现，即需要在事务预提交阶段获取所有数据行的写锁，如果获取某行写锁失败，则整个事务执行失败。</li>
  <li>读写事务（read committed）<br />
  读写事务中的读操作读取某个版本的快照，写操作的加锁方式与只写事务相同。 为了保证系统并发性能，OceanBase暂时不支持更高的隔离级别。另外，为了支持对一致性要求很高的业务，OceanBase允许用户显式锁住某个数据行。例如，有一张账务表account（account_id, balance），其中account_id为主键。假设需要从A账户（account_id=1）向B账户（account_id=2）转账100元，那么A账户需要减少100元，B账户需要增加100元，整个转账操作是一个事务，执行过程中需要防止A账户和B账户被其它事务并发修改。</li>
</ul>
<p>如<a href="#f_3_12"><b>图3-12</b></a>所示，OceanBase提供了”select … for update”语句用于显示锁住A账户或者B账户，防止转账过程中被其它事务并发修改。</p>
<p><b><a name="f_3_12" id="f_3_12"></a>图3-12 select … for update示例</b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_12.png?raw=true" /></p>
<p>事务执行过程中可能会发生死锁，例如事务T1持有账户A的写锁并尝试获取账户B的写锁，事务T2持有账户B的写锁并尝试获取账户A的写锁，这两个事务因为循环等待而出现死锁。OceanBase目前处理死锁的方式很简单，事务执行过程中如果超过一定时间无法获取写锁，则自动回滚。</p>
<h4>* 多线程并发日志回放</h4>
<p>在本手册的“3.2.3	多表操作”章节介绍了主备同步原理。引入多版本并发控制机制后，UpdateServer备机支持多线程并发回放日志功能。如<b><a href="#f_3_13">图3-13</a></b>所示，有一个日志分发线程每次从日志源读取一批日志，拆分为单独的日志回放任务交给不同的日志回放线程处理。一批日志回放完成时，日志提交线程会将对应的事务提交到MemTable并将日志内容持久化到日志文件。</p>
<p><b><a name="f_3_13" id="f_3_13"></a>图3-13 备机多线程并发日志回放</b></p>
<p><img src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_13.png?raw=true" alt="" /></p>
<h2>3.4  OLAP业务支持</h2>
<p>OLAP业务的特点是SQL每次执行涉及的数据量很大，需要一次性分析几百万行甚至几千万行的数据。另外， SQL执行时往往只读取每行的部分列而不是整行数据。为了支持OLAP计算，OceanBase主要实现并发查询功能。</p>
<p>如<a href="#f_3_14"><b>图3-14</b></a>所示，MergeServer将大请求拆分为多个子请求，同时发往每个子请求所在的ChunkServer并发执行，每个ChunkServer执行子请求并将部分结果返回给MergeServer。MergeServer合并ChunkServer返回的部分结果并将最终结果返回给客户端。</p>
<p><b><a name="f_3_14" id="f_3_14"></a>图3-14 OceanBase并发查询 </b></p>
<p><img alt="" src="https://github.com/alibaba/oceanbase/blob/oceanbase_0.4/doc/picture/Description/3_14.png?raw=true" /></p>
<p>MergeServer并发查询执行步骤如下：</p>
<ol>
  <li> MergeServer解析SQL语句，根据本地缓存的Tablet位置信息获取需要请求的ChunkServer。</li>
  <li>如果请求只涉及一个Tablet，将请求发送给该Tablet所在的ChunkServer执行；如果请求涉及多个Tablet，将请求按照Tablet拆分为多个子请求，每个子请求对应一个Tablet，并发送给该Tablet所在的ChunkServer并发执行。MergeServer等待每个子请求的返回结果。</li>
  <li>ChunkServer执行子请求，计算子请求的部分结果。SQL执行遵从“3.2.4 SQL执行本地化”章节提到的本地化原则，即能让ChunkServer执行的尽量让ChunkServer执行，包括Filter、Project、子请求部分结果的GroupBy、OrderBy、聚合运算等。</li>
  <li>每个子请求执行完成后，ChunkServer将执行结果回复MergeServer，MergeServer首先将每个子请求的执行结果保存起来。如果某个子请求执行失败，MergeServer会将该子请求发往Tablet其它副本所在的ChunkServer执行。</li>
  <li>等到所有的子请求执行完成后，MergeServer会对全部数据排序、分组、聚合并将最终结果返回给客户。</li>
</ol>
<p>OceanBase支持multiget操作一次性读取多行数据，且读取的数据可能在不同的ChunkServer上。对于这样的操作，MergeServer会按照ChunkServer拆分子请求，每个子请求对应一个ChunkServer。假设客户端请求5行数据，其中第1、3、5行在ChunkServer A上，第2、4行在ChunkServer B上。那么，该请求将被拆分为（1、3、5）和（2、4）两个子请求，分别发往ChunkServer A和B。</p>
<p>细心的读者可能会发现，OceanBase这种查询模式虽然解决了绝大部分大查询请求的延时问题，但是如果查询的返回结果特别大，MergeServer将成为性能瓶颈。因此，新版的OceanBase系统将对OLAP查询执行逻辑进行升级，使其能够支持更加复杂的SQL查询。</p>
<h2>3.5  特色功能</h2>
<p>虽然OceanBase是一个通用的分布式关系数据库，然而在阿里巴巴集团落地过程中，为了满足业务的需求，也实现了一些特色功能。这些功能在互联网应用中很常见，但在传统的关系数据库中往往实现得比较低效。本节介绍其中两个具有代表性的功能，分别为“大表左连接”和“数据过期与批量删除”。</p>
<h3>3.5.1   大表左连接</h3>
<p>大表左连接需求来源于淘宝收藏夹业务。简单来讲，收藏夹业务包含两张表格：收藏表collect_info和商品表collect_item。collect_info表存储了用户的收藏信息，比如收藏时间、标签等；collect_item存储了用户收藏的商品或者店铺的信息，包括价格、人气等。Collect_info的数据条目达到100亿条，collect_item的数据条目接近10亿条，每个用户平均收藏了50~100个商品或者店铺。用户可以按照收藏时间浏览收藏项，也可以对收藏项按照价格、人气排序。常见的实现方法有以下两种：</p>
<ul>
  <li>直接采用关系数据库Join操作实现<br />
  根据collect_info中存储的商品编号（item_id），实时地从商品表读取商品的价格、人气等信息。然而，当商品表数据量较大时，需要分库分表后分布到多台数据库服务器，即使是同一个用户收藏的商品也会被打散到多台服务器。某些用户收藏了几千个商品或者店铺，如果需要从很多台服务器读取几千条数据，整体延时是不可接受的，系统的并发能力也将受限。</li>
  <li>冗余<br />
  在collect_info表中冗余商品的价格、人气等信息，那么读取时则不需要读取collect_item表。然而，热门商品可能被数十万个用户收藏，每次价格、人气发生变化时都需要修改数十万个用户的收藏条目。显然，这是不可接受的。</li>
</ul>
<p>这个问题本质上是一个大表左连接（Left Join）的问题，连接列为item_id，即右表（商品表）的主键。对于这个问题，OceanBase的做法是在collect_info的基准数据中冗余collect_item信息，修改增量中将collect_info和collect_item两张表格分开存储。商品价格、人气变化信息只需要记录在UpdateServer的修改增量中，读取操作步骤如下：</p>
<ol>
  <li>
    从ChunkServer读取collect_info表格的基准数据（冗余了collect_item信息）。  </li>
  <li>从UpdateServer读取collect_info表格的修改增量，并融合到“步骤1”的结果中。</li>
  <li>从UpdateServer读取collect_item表格中每个收藏商品的修改增量，并融合到“步骤2”的结果中。</li>
  <li> 对“步骤3”生成的结果执行排序（按照人气、价格等），分页等操作并返回给客户端。  </li>
</ol>
<p>OceanBase的实现方式得益于每天业务低峰期进行的每日合并操作。每日合并时，ChunkServer会将UpdateServer上collect_info和collect_item表格中的修改增量融合到collect_info表格的基准数据中，生成新的基准数据。因此，collect_info和collect_item的数据量不至于太大，从而能够存放到单台机器的内存中提供高效查询服务。</p>
<h3>3.5.2   数据过期与批量删除</h3>
<p>很多业务只需要存储一段时间（比如三个月或者半年的数据），更早之前的数据可以被丢弃从而节省存储成本。OceanBase支持数据自动过期功能。</p>
<p>OceanBase线上每个表格都包含创建时间（gmt_create）和修改时间（gmt_modified）列。使用者可以设置自动过期规则，比如只保留创建时间或修改时间不晚于某个时间点的数据行，读取操作会根据规则过滤这些失效的数据行，每日合并时这些数据行会被物理删除。</p>
<p>批量删除需求来源于OLAP业务。这些业务往往每天导入一批数据，由于业务逻辑复杂，上游系统很可能出错，导致某一天导入的数据出现问题，需要将这部分出错的数据删除掉。由于导入的数据量较大，一条一条删除其中的数据是不现实的。因此，OceanBase实现了批量删除功能，具体做法和数据自动过期功能类似。使用者可以增加一个删除规则，比如删除创建时间在某个时间段的数据行，以后所有的读操作都会自动过滤这些出错的数据行，每日合并时这些出错的数据行会被物理删除。</p>